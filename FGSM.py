import cv2
#import keras
from tensorflow import keras
#import tensorflow as tf
import tensorflow as tf
#import tensorflow.compat.v1 as tf
from tensorflow.python.platform import app
from tensorflow.python.platform import flags

import sys
import warnings
import os
from math import log
from sklearn.model_selection import train_test_split
import pandas as pd

import numpy as np
import keras
from keras import backend
from keras.models import load_model
import tensorflow as tf
from keras.models import Sequential
from keras.optimizers import SGD
from keras.utils import np_utils
from keras.layers import Input, Dense
from keras.models import Model
from keras.layers import Dropout, Flatten, Dense, Conv1D, Conv2D, Activation, MaxPooling2D, GlobalMaxPooling1D, GlobalMaxPooling2D, Input, Embedding, Multiply, MaxPooling1D,GlobalAveragePooling2D, GlobalAveragePooling1D
from cleverhans.attacks import FastGradientMethod
from cleverhans.attacks import BasicIterativeMethod
from cleverhans.utils_keras import KerasModelWrapper
from cleverhans.utils_tf import model_eval
from cleverhans.utils_tf import batch_eval
from cleverhans.utils_tf import model_train
from cleverhans.utils import AccuracyReport
from cleverhans.train import train
#from tensorflow import keras
from matplotlib import pyplot as plt
import cv2

# Set TF random seed to improve reproducibility
tf.set_random_seed(1234)
if keras.backend.image_data_format() != 'channels_last':
    raise NotImplementedError("this tutorial requires keras to be configured to channels_last format")

# Create TF session and set as Keras backend session
sess = tf.compat.v1.Session()
keras.backend.set_session(sess)
BATCH_SIZE = 128
batch_size = BATCH_SIZE
print("Created TensorFlow session and set Keras backend.")
backend.set_learning_phase(False)
keras_model = load_model('final_model.h5')
keras_model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True, decay=1e-6), metrics=['accuracy'])

# Load dataset
path_root = 'mal_dataset\\'
from keras.preprocessing.image import ImageDataGenerator
batches = ImageDataGenerator().flow_from_directory(directory=path_root, target_size=(224, 224),color_mode="grayscale", batch_size=12000)
batches.class_indices
imgs, labels = next(batches)
# print(imgs.shape)
# print(labels.shape)
# # Split data
# seed = 27
X_train, X_test, y_train, y_test = train_test_split(imgs, labels,test_size=0.2)
X_test =X_test[0:200]
y_test= y_test[0:200]
X_train, X_test = X_train / 255.0, X_test / 255.0
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)
#
# # Define TF model graph
#
img_rows, img_cols, nchannels = X_train.shape[1:4]
nb_classes = y_train.shape[1]
print(nb_classes)
x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,nchannels))
y = tf.placeholder(tf.float32, shape=(None, nb_classes))
#
#
# # Evaluate the model's accuracy on the validation data used in training
#
predictions = keras_model(x)
# print("Defined TensorFlow model graph.")
# # Train the model
nb_epoch = 10
# learning_rate = 0.001
# from keras.callbacks import EarlyStopping
# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)
# train_params = {
#     'nb_epochs': nb_epoch,
#     'batch_size': batch_size,
#     'learning_rate': learning_rate,
#     'callbacks': [es]
# }
# #model_train(sess, x, y, predictions, X_train, y_train,args=train_params)
# # Evaluate the accuracy of the model on legitimate test examples
eval_par = {'batch_size': batch_size}
accuracy = model_eval(sess, x, y, predictions, X_test, y_test,args=eval_par)
# #assert X_test.shape[0] == 10000, X_test.shape
print('Test accuracy on legitimate test examples: ' + str(accuracy))
#
"""
path_dir = 'output/val'
batches = ImageDataGenerator().flow_from_directory(directory=path_dir, target_size=(224, 224), color_mode="grayscale", batch_size=3000)
batches.class_indices
imgs, labels = next(batches)
print(imgs.shape)
print(labels.shape)

img_rows, img_cols, nchannels = imgs.shape[1:4]
nb_classes = labels.shape[1]
print(nb_classes)
x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,nchannels))
y = tf.placeholder(tf.float32, shape=(None, nb_classes))
"""
# # Craft adversarial examples using Fast Gradient Sign Method (FGSM)
wrap = KerasModelWrapper(keras_model)
fgsm = FastGradientMethod(wrap, sess=sess)
fgsm_params = {'eps': 0.03}
"""
fgsm_params = {'eps': 0.025,
                   'clip_min': 0.,
                   'clip_max': 1.}
"""
adv_x = fgsm.generate(x, **fgsm_params)
preds_adv = keras_model(adv_x)
# # Consider the attack to be constant
#adv_x = tf.stop_gradient(adv_x)
preds_adv = keras_model(adv_x)
# #images= np.ones((11702,224,224,1))
# #with tf.Session() as sess:

x_adv = sess.run(adv_x, feed_dict={x: X_test})
#y_adv_benign = os.listdir("output/val/benign") # 169
#y_adv_malware = os.listdir("output/val/malware")[2131:2172]
# y_adv = os.path.join("output/val/benign", "output/val/malware")
# # x_adv = sess.run(adv_x, feed_dict={x: x_placeholder })
# print("y_adv",y_adv)
# print("y_adv shape",y_adv.shape)
# print("done")
#for i in range(len(x_adv)):
   # print(i, y_adv_malware[i])
    #x_adv_norm = x_adv[i]/(x_adv[i].max()/255.0)
    #cv2.imwrite("adv/malware/{}".format(y_adv_malware[i]), x_adv_norm)
#print("imgs saved")
# preds_adv = keras_model(adv_x)
#print("DONE")

#exit()

#keras_model(x_adv)
# x_adv_norm = x_adv.transpose(0,2,3,1).squeeze(0)
# x_adv_norm = (x_adv_norm - x_adv_norm.min()) / (x_adv_norm.max() - x_adv_norm.min())
# x_adv_norm = (x_adv_norm * 255).astype(np.uint8)

# for i in range(len(x_adv)):
#     x_adv_norm = x_adv[i]/(x_adv[i].max()/255.0)
#     cv2.imwrite("adv_images/adv_img_{}.png".format(i), x_adv_norm)
# print("img saved")
# exit()
#y_pred = np.argmax(keras_model.predict(x_adv[0]), axis=-1)
#print(x_adv[0].shape)
#print(y_pred)
#exit()
# Evaluate the accuracy of the MNIST model on adversarial examples
accuracy = model_eval(sess, x, y, preds_adv, X_test, y_test,args=eval_par)
print('Test accuracy on adversarial examples: ' + str(accuracy))

#print("Repeating the process, using adversarial training")
# Redefine TF model graph
#predictions_2 = keras_model(x)
#adv_x_2 = fgsm.generate(x, **fgsm_params)
#predictions_2_adv = keras_model(adv_x_2)

# Perform adversarial training
#model_train(sess, x, y, predictions_2, X_train, y_train, args=train_params,predictions_adv=predictions_2_adv)

# Evaluate the accuracy of the adversarialy trained MNIST model on
# legitimate test examples
#accuracy = model_eval(sess, x, y, predictions_2, X_test, y_test, args=eval_par)
#print('Test accuracy on legitimate test examples: ' + str(accuracy))

# Craft adversarial examples using Fast Gradient Sign Method (FGSM) on
# the new model, which was trained using adversarial training
#X_test_adv_2 = batch_eval(sess, [x], [adv_x_2], [X_test])
#assert X_test_adv_2.shape[0] == 10000, X_test_adv_2.shape

# Evaluate the accuracy of the adversarially trained MNIST model on
# adversarial examples
#accuracy_adv = model_eval(sess, x, y, predictions_2_adv, X_test, y_test,args=eval_par)
#print('Test accuracy on adversarial examples: ' + str(accuracy_adv))

#X_test_adv= batch_eval(sess, [x], [adv_x], [X_test])
#array = np.arange(X_test_adv)
#Saving Image
from PIL import Image
import cv2
#from scipy.misc import imread
#from scipy.misc import imsave

import scipy.misc
"""
normal_digit_pred = np.argmax(keras_model.predict(X_test), axis = 1)
print(normal_digit_pred)
adv_digit_pred = np.argmax(keras_model.predict(x_adv), axis = 1)
print("adv_pred_result",adv_digit_pred)
print("adv_pred_shape",adv_digit_pred.shape)
"""
#for i in range(len(x_adv)):
    #x_adv_norm = x_adv[i]/(x_adv[i].max()/255.0)
    #if adv_digit_pred[i] == 0:
        #cv2.imwrite("adv_images/{}/adv_img_{}.png".format("benign", i+1000), x_adv_norm)
    #else:
        #cv2.imwrite("adv_images/{}/adv_img_{}.png".format("malware", i+1000), x_adv_norm)
#print("img saved")
#exit()


#scipy.misc.imsave('outfile.jpg', x_adv)
# Define a function that stitches the 28 * 28 numpy arrays
# together into a collage.
"""
def stitch_images(images, y_img_count, x_img_count, margin = 2):

    # Dimensions of the images
    img_width = images[0].shape[0]
    img_height = images[0].shape[1]

    width = y_img_count * img_width + (y_img_count - 1) * margin
    height = x_img_count * img_height + (x_img_count - 1) * margin
    stitched_images = np.zeros((width, height, 3))

    # Fill the picture with our saved filters
    for i in range(y_img_count):
        for j in range(x_img_count):
            img = images[i * x_img_count + j]
            if len(img.shape) == 2:
                img = np.dstack([img] * 3)
            stitched_images[(img_width + margin) * i: (img_width + margin) * i + img_width,
                            (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img

    return stitched_images

x_sample = X_test[0]
adv_x_sample = x_adv[0]

adv_comparison = stitch_images([x_sample, adv_x_sample], 1, 2)

plt.imshow(adv_comparison)
plt.show()
"""






























